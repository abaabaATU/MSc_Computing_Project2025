{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "756f9ab0",
   "metadata": {},
   "source": [
    "# TE, PID, PhiID analysis\n",
    "\n",
    "main output: in results/, one file per condition (10 in total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c996cc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from analysis.utils import demean\n",
    "\n",
    "# Load data\n",
    "with open('merged_data.pkl', 'rb') as f:\n",
    "    merged_data = pickle.load(f)\n",
    "\n",
    "# Process each condition while preserving structure\n",
    "for condition, data_dict in merged_data.items():\n",
    "    if condition == 'roi_names':  # Skip the roi_names entry if it exists at top level\n",
    "        continue\n",
    "        \n",
    "    # Demean and update in-place to preserve all other fields (e.g., 'stim_roi')\n",
    "    data_dict['data'] = demean(data_dict['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a29c245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Condition MOp (L) original shape: (130, 30, 8)\n",
      "Deleted source: 1\n",
      "Condition MOp (L) new shape: (130, 30, 7)\n",
      "Remaining trials: 7\n",
      "\n",
      "Condition RSPd/v (Bilateral) original shape: (130, 30, 8)\n",
      "Deleted source: 7\n",
      "Condition RSPd/v (Bilateral) new shape: (130, 30, 7)\n",
      "Remaining trials: 7\n",
      "\n",
      "Condition SSp-bfd (L) original shape: (130, 30, 8)\n",
      "Deleted source: 7\n",
      "Condition SSp-bfd (L) new shape: (130, 30, 7)\n",
      "Remaining trials: 7\n"
     ]
    }
   ],
   "source": [
    "def delete_trial(merged_data, cond, trial_num):\n",
    "    \"\"\"\n",
    "    Delete specified trial data and corresponding metadata from merged dataset\n",
    "    \n",
    "    Args:\n",
    "        merged_data: Merged dataset dictionary\n",
    "        cond: Condition name (e.g. 'MOp (L)')\n",
    "        trial_num: Trial index to delete (0-based)\n",
    "    \"\"\"\n",
    "    if cond not in merged_data:\n",
    "        print(f\"Warning: Condition {cond} not found\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nCondition {cond} original shape: {merged_data[cond]['data'].shape}\")\n",
    "    \n",
    "    # Delete trial from data matrix\n",
    "    merged_data[cond]['data'] = np.delete(merged_data[cond]['data'], trial_num, axis=2)\n",
    "    \n",
    "    # Remove corresponding source info\n",
    "    if 'sources' in merged_data[cond] and isinstance(merged_data[cond]['sources'], list):\n",
    "        if len(merged_data[cond]['sources']) > trial_num:\n",
    "            deleted_source = merged_data[cond]['sources'].pop(trial_num)\n",
    "            print(f\"Deleted source: {deleted_source}\")\n",
    "    \n",
    "    # Update analysis results (PID/PhiID/TE) if present\n",
    "    for analysis_type in ['PID', 'PhiID', 'TE']:\n",
    "        if analysis_type in merged_data[cond]:\n",
    "            for key in merged_data[cond][analysis_type]:\n",
    "                if isinstance(merged_data[cond][analysis_type][key], np.ndarray) and merged_data[cond][analysis_type][key].ndim >= 2:\n",
    "                    merged_data[cond][analysis_type][key] = np.delete(merged_data[cond][analysis_type][key], trial_num, axis=-1)\n",
    "    \n",
    "    # Update trial count in metadata\n",
    "    if 'metadata' in merged_data[cond] and 'n_trials' in merged_data[cond]['metadata']:\n",
    "        merged_data[cond]['metadata']['n_trials'] -= 1\n",
    "    \n",
    "    print(f\"Condition {cond} new shape: {merged_data[cond]['data'].shape}\")\n",
    "    print(f\"Remaining trials: {len(merged_data[cond]['sources'])}\")\n",
    "\n",
    "delete_trial(merged_data, 'MOp (L)', 0)\n",
    "delete_trial(merged_data, 'RSPd/v (Bilateral)', 6)\n",
    "delete_trial(merged_data, 'SSp-bfd (L)', 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35fbc22",
   "metadata": {},
   "source": [
    "\n",
    "# Compare the changes in information flow between the same pair of ROIs during resting state and stimulated state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eeadc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np       \n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from analysis.VAR_NuMIT import PID_VAR_calculator, PhiID_VAR_calculator\n",
    "import logging\n",
    "from functools import partial\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2078fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_roi_pairs(merged_data, maxp=1, n_workers=3, selected_conditions=None):\n",
    "    \"\"\"\n",
    "    Optimized ROI pair analysis with selective condition processing\n",
    "    \n",
    "    Args:\n",
    "        merged_data: Merged dataset {'roi_names': list, cond: {'data': ndarray}}\n",
    "        maxp: Maximum VAR model order\n",
    "        n_workers: Number of parallel workers\n",
    "        selected_conditions: List of conditions to process (names/indices), None for all\n",
    "    Returns:\n",
    "        Structured analysis results dictionary\n",
    "    \"\"\"\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    logger = logging.getLogger(__name__)\n",
    "    \n",
    "    all_conditions = [c for c in merged_data.keys() if c != 'roi_names']\n",
    "    \n",
    "    if selected_conditions is None:\n",
    "        conditions_to_run = all_conditions\n",
    "    else:\n",
    "        conditions_to_run = []\n",
    "        for cond in selected_conditions:\n",
    "            if isinstance(cond, int) and 0 <= cond < len(all_conditions):\n",
    "                conditions_to_run.append(all_conditions[cond])\n",
    "            elif cond in all_conditions:\n",
    "                conditions_to_run.append(cond)\n",
    "            else:\n",
    "                logger.warning(f\"Condition {cond} not found, skipping\")\n",
    "    \n",
    "    results = {\n",
    "        'metadata': {\n",
    "            'date': datetime.now().strftime(\"%Y-%m-%d\"),\n",
    "            'maxp': maxp,\n",
    "            'all_conditions': all_conditions,\n",
    "            'selected_conditions': conditions_to_run,\n",
    "            'roi_names': merged_data['roi_names'],\n",
    "            'analysis_type': 'multimodal_trial_analysis'\n",
    "        },\n",
    "        'conditions': {}\n",
    "    }\n",
    "\n",
    "    pid_atoms = ['R', 'U_X', 'U_Y', 'S']\n",
    "    phiid_atoms = [\n",
    "        'rtr', 'rtx', 'rty', 'rts',\n",
    "        'xtr', 'xtx', 'xty', 'xts',\n",
    "        'ytr', 'ytx', 'yty', 'yts',\n",
    "        'str', 'stx', 'sty', 'sts'\n",
    "    ]\n",
    "    roi_names = merged_data['roi_names']\n",
    "\n",
    "    dims = {}\n",
    "    for cond in conditions_to_run:\n",
    "        data_dict = merged_data[cond]\n",
    "        min_time = min(data.shape[0] for data in data_dict['data'])\n",
    "        min_trials = min(data.shape[1] for data in data_dict['data'])\n",
    "        dims[cond] = (min_time, min_trials)\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=n_workers) as executor:\n",
    "        futures = {}\n",
    "        for cond in conditions_to_run:\n",
    "            futures[executor.submit(process_condition, \n",
    "                                  cond, merged_data[cond], roi_names, \n",
    "                                  dims[cond], maxp, pid_atoms, phiid_atoms,\n",
    "                                  merged_data[cond].get('sources', []))] = cond\n",
    "        \n",
    "        for future in as_completed(futures):\n",
    "            cond = futures[future]\n",
    "            try:\n",
    "                cond_results = future.result()\n",
    "                results['conditions'][cond] = cond_results\n",
    "                logger.info(f\"Completed processing condition: {cond}\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error processing condition {cond}: {str(e)}\")\n",
    "                results['conditions'][cond] = {\n",
    "                    'error': str(e),\n",
    "                    'roi_pairs': {},\n",
    "                    'activation_changes': [],\n",
    "                    'TE': {'summary_stats': [], 'trial_level_data': []},\n",
    "                    'PID': {'summary_stats': [], 'trial_level_data': []},\n",
    "                    'PhiID': {'summary_stats': [], 'trial_level_data': []}\n",
    "                }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def process_condition(cond, data_dict, roi_names, dims, maxp, pid_atoms, phiid_atoms, sources):\n",
    "    \"\"\"Process analysis for a single condition\"\"\"\n",
    "    logger = logging.getLogger(__name__)\n",
    "    min_time, min_trials = dims\n",
    "    n_rois = len(roi_names)\n",
    "    \n",
    "    cond_results = {\n",
    "        'roi_pairs': {},\n",
    "        'activation_changes': [],\n",
    "        'TE': {'summary_stats': [], 'trial_level_data': []},\n",
    "        'PID': {'summary_stats': [], 'trial_level_data': []},\n",
    "        'PhiID': {'summary_stats': [], 'trial_level_data': []},\n",
    "        'trial_sources': sources\n",
    "    }\n",
    "    \n",
    "    logger.info(f\"Processing condition: {cond} with {min_trials} trials\")\n",
    "\n",
    "    roi_pairs = [(i, j) for i in range(n_rois) for j in range(n_rois) if i != j]\n",
    "    \n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        process_pair_partial = partial(process_roi_pair, \n",
    "                                     cond=cond, data_dict=data_dict, \n",
    "                                     roi_names=roi_names, min_time=min_time,\n",
    "                                     min_trials=min_trials, maxp=maxp,\n",
    "                                     pid_atoms=pid_atoms, phiid_atoms=phiid_atoms)\n",
    "        \n",
    "        futures = {executor.submit(process_pair_partial, i, j): (i, j) for i, j in roi_pairs}\n",
    "        \n",
    "        for future in as_completed(futures):\n",
    "            i, j = futures[future]\n",
    "            roi1_name, roi2_name = roi_names[i], roi_names[j]\n",
    "            pair_key = f\"{roi1_name}_vs_{roi2_name}\"\n",
    "            \n",
    "            try:\n",
    "                pair_results = future.result()\n",
    "                cond_results['roi_pairs'][pair_key] = pair_results\n",
    "                logger.debug(f\"Completed ROI pair: {pair_key}\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error processing ROI pair {pair_key}: {str(e)}\")\n",
    "                cond_results['roi_pairs'][pair_key] = {\n",
    "                    'error': str(e),\n",
    "                    'roi_info': {'names': [roi1_name, roi2_name], 'indices': [i, j]},\n",
    "                    'VAR': {'p_opt': None, 'A': [], 'V': []},\n",
    "                    'TE': {'values': [], 'mean': None},\n",
    "                    'PID': {'trial_values': defaultdict(list), 'mean': {}},\n",
    "                    'PhiID': {'trial_values': defaultdict(list), 'mean': {}}\n",
    "                }\n",
    "\n",
    "    return cond_results\n",
    "\n",
    "def process_roi_pair(i, j, cond, data_dict, roi_names, min_time, min_trials, maxp, pid_atoms, phiid_atoms):\n",
    "    \"\"\"Process analysis for a single ROI pair\"\"\"\n",
    "    logger = logging.getLogger(__name__)\n",
    "    roi1_name, roi2_name = roi_names[i], roi_names[j]\n",
    "    pair_key = f\"{roi1_name}_vs_{roi2_name}\"\n",
    "    \n",
    "    pair_results = {\n",
    "        'roi_info': {'names': [roi1_name, roi2_name], 'indices': [i, j]},\n",
    "        'VAR': {'p_opt': None, 'A': [], 'V': []},\n",
    "        'TE': {'values': [], 'mean': None, 'trial_sources': []}, \n",
    "        'PID': {'trial_values': defaultdict(list), 'mean': {}, 'trial_sources': []},\n",
    "        'PhiID': {'trial_values': defaultdict(list), 'mean': {}, 'trial_sources': []}\n",
    "    }\n",
    "\n",
    "    data_roi1 = data_dict['data'][i, :, :]\n",
    "    data_roi2 = data_dict['data'][j, :, :]\n",
    "    sources = data_dict.get('sources', [None]*min_trials)\n",
    "    \n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = {}\n",
    "        for trial in range(min_trials):\n",
    "            futures[executor.submit(process_trial, \n",
    "                                    trial, data_roi1, data_roi2, \n",
    "                                    min_time, maxp, pid_atoms, phiid_atoms,\n",
    "                                    sources[trial] if trial < len(sources) else None)] = trial\n",
    "        \n",
    "        for future in as_completed(futures):\n",
    "            trial = futures[future]\n",
    "            try:\n",
    "                trial_result = future.result()\n",
    "                if trial_result is not None:\n",
    "                    p_opt, A, V, te, pid, phiid, source = trial_result\n",
    "                    \n",
    "                    pair_results['VAR']['p_opt'] = p_opt\n",
    "                    pair_results['VAR']['A'].append(A)\n",
    "                    pair_results['VAR']['V'].append(V)\n",
    "                    \n",
    "                    pair_results['TE']['values'].append(te)\n",
    "                    pair_results['TE']['trial_sources'].append(source)\n",
    "                    \n",
    "                    for a, atom in enumerate(pid_atoms):\n",
    "                        pair_results['PID']['trial_values'][atom].append(float(pid[a]))\n",
    "                    pair_results['PID']['trial_sources'].append(source)\n",
    "\n",
    "                    for a, atom in enumerate(phiid_atoms):\n",
    "                        pair_results['PhiID']['trial_values'][atom].append(float(phiid[a]))\n",
    "                    pair_results['PhiID']['trial_sources'].append(source)\n",
    "                        \n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Error processing trial {trial} for pair {pair_key}: {str(e)}\")\n",
    "                continue\n",
    "    \n",
    "    if pair_results['TE']['values']:\n",
    "        pair_results['TE']['mean'] = np.nanmean(pair_results['TE']['values'])\n",
    "        \n",
    "        for atom in pid_atoms:\n",
    "            if atom in pair_results['PID']['trial_values']:\n",
    "                pair_results['PID']['mean'][atom] = np.nanmean(pair_results['PID']['trial_values'][atom])\n",
    "        \n",
    "        for atom in phiid_atoms:\n",
    "            if atom in pair_results['PhiID']['trial_values']:\n",
    "                pair_results['PhiID']['mean'][atom] = np.nanmean(pair_results['PhiID']['trial_values'][atom])\n",
    "    \n",
    "    return pair_results\n",
    "\n",
    "def process_trial(trial, data_roi1, data_roi2, min_time, maxp, source):\n",
    "    \"\"\"Process calculations for a single trial\"\"\"\n",
    "    roi1 = data_roi1[:min_time, trial:trial+1]\n",
    "    roi2 = data_roi2[:min_time, trial:trial+1]\n",
    "    combined = np.stack([roi1, roi2], axis=0)\n",
    "    \n",
    "    p_opt, A, V = fit_and_select_model(combined, maxp)\n",
    "    te = calculate_te(A, V)[0,1]\n",
    "    \n",
    "    if np.isnan(te).any():\n",
    "        raise ValueError(\"NaN values in TE calculation\")\n",
    "    \n",
    "    pid = PID_VAR_calculator(p=p_opt, A=A, V=V, L1=1, L2=1)[0]\n",
    "    phiid = PhiID_VAR_calculator(p=p_opt, A=A, V=V, L1=1, L2=1)[0]\n",
    "    \n",
    "    return p_opt, A, V, te, pid, phiid, source\n",
    "\n",
    "\n",
    "def fit_and_select_model(data, maxp, fixed_p=None):\n",
    "    \"\"\"Fit VAR model and select optimal order\"\"\"\n",
    "    from analysis.VAR_fitness import tsdata_to_varmo, fit_var\n",
    "    \n",
    "    if fixed_p is not None:\n",
    "        p_opt = fixed_p\n",
    "    else:\n",
    "        p_opt, _, _ = tsdata_to_varmo(data, maxp)[:3]\n",
    "        p_opt = max(1, p_opt)  # Ensure minimum order of 1\n",
    "    \n",
    "    A, V, _ = fit_var(data, p=p_opt)\n",
    "    return p_opt, A, V\n",
    "\n",
    "def calculate_te(A, V):\n",
    "    \"\"\"Calculate transfer entropy matrix\"\"\"\n",
    "    n = A.shape[1]\n",
    "    te_matrix = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i != j and V[i,i] > 1e-6:\n",
    "                te_matrix[i,j] = 0.5 * np.log(V[j,j] / (V[j,j] - V[j,i]**2/V[i,i]))\n",
    "    return te_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff54043b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pickle\n",
    "\n",
    "def save_results(results, cond=None, output_dir='results'):\n",
    "    \"\"\"\n",
    "    Save analysis results in both .npz and .pkl formats with timestamp\n",
    "    \n",
    "    Args:\n",
    "        results: Analysis results dictionary to save\n",
    "        cond: Condition name (optional)\n",
    "        output_dir: Output directory (default 'results')\n",
    "    \n",
    "    Returns:\n",
    "        List of saved file paths [npz_path, pkl_path]\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Prepare data for saving\n",
    "    save_dict = {}\n",
    "    for key, value in results.items():\n",
    "        if not isinstance(value, (np.ndarray, str, int, float, bool)):\n",
    "            try:\n",
    "                value = np.array(value)\n",
    "            except:\n",
    "                value = str(value)\n",
    "        save_dict[key] = value\n",
    "    \n",
    "    # Generate filename\n",
    "    if cond is None and 'metadata' in results:\n",
    "        cond = '_'.join(results.get('metadata', {}).get('selected_conditions', []))\n",
    "    \n",
    "    if cond:\n",
    "        safe_cond = re.sub(r'[\\\\/*?:\"<>|]', '_', str(cond))\n",
    "        basename = f\"results_{safe_cond}\"\n",
    "    else:\n",
    "        basename = \"results_all\"\n",
    "    \n",
    "    # Save .npz format\n",
    "    npz_path = os.path.join(output_dir, f\"{basename}.npz\")\n",
    "    try:\n",
    "        np.savez_compressed(npz_path, **save_dict)\n",
    "    except Exception as e:\n",
    "        np.savez(npz_path, **save_dict)\n",
    "        print(f\"Used uncompressed .npz format due to: {str(e)}\")\n",
    "    \n",
    "    # Save .pkl format\n",
    "    pkl_path = os.path.join(output_dir, f\"{basename}.pkl\")\n",
    "    try:\n",
    "        with open(pkl_path, 'wb') as f:\n",
    "            pickle.dump(results, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving .pkl file: {str(e)}\")\n",
    "        try:\n",
    "            with open(pkl_path, 'wb') as f:\n",
    "                pickle.dump(save_dict, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to save simplified .pkl file: {str(e)}\")\n",
    "            pkl_path = None\n",
    "    \n",
    "    print(f\"Results saved to:\\n- {npz_path}\\n- {pkl_path if pkl_path else 'Failed to save .pkl file'}\")\n",
    "    \n",
    "    return [npz_path, pkl_path] if pkl_path else [npz_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a914882",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Processing condition: Rest with 17 trials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Rest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Completed processing condition: Rest\n",
      "INFO:__main__:Processing condition: MOp (L) with 7 trials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to:\n",
      "- results/results_Rest.npz\n",
      "- results/results_Rest.pkl\n",
      "\n",
      "Processing MOp (L)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Completed processing condition: MOp (L)\n",
      "INFO:__main__:Processing condition: VISam/pm (R) with 14 trials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to:\n",
      "- results/results_MOp (L).npz\n",
      "- results/results_MOp (L).pkl\n",
      "\n",
      "Processing VISam/pm (R)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Completed processing condition: VISam/pm (R)\n",
      "INFO:__main__:Processing condition: AUD (L) with 14 trials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to:\n",
      "- results/results_VISam_pm (R).npz\n",
      "- results/results_VISam_pm (R).pkl\n",
      "\n",
      "Processing AUD (L)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Completed processing condition: AUD (L)\n",
      "INFO:__main__:Processing condition: SSp-ul/ll (R) with 8 trials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to:\n",
      "- results/results_AUD (L).npz\n",
      "- results/results_AUD (L).pkl\n",
      "\n",
      "Processing SSp-ul/ll (R)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:__main__:Error processing trial 5 for pair SSp-ll (R)_vs_PPN (R): Matrix is not positive definite.\n",
      "WARNING:__main__:Error processing trial 5 for pair SSp-ll (R)_vs_PAL (R): Matrix is not positive definite.\n",
      "WARNING:__main__:Error processing trial 5 for pair SSp-ll (R)_vs_MOs (L): Matrix is not positive definite.\n",
      "WARNING:__main__:Error processing trial 5 for pair PPN (R)_vs_SSp-ll (R): Matrix is not positive definite.\n",
      "WARNING:__main__:Error processing trial 5 for pair PAL (R)_vs_SSp-ll (R): Matrix is not positive definite.\n",
      "WARNING:__main__:Error processing trial 5 for pair MOs (L)_vs_SSp-ll (R): Matrix is not positive definite.\n",
      "INFO:__main__:Completed processing condition: SSp-ul/ll (R)\n",
      "INFO:__main__:Processing condition: RSPd/v (Bilateral) with 7 trials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to:\n",
      "- results/results_SSp-ul_ll (R).npz\n",
      "- results/results_SSp-ul_ll (R).pkl\n",
      "\n",
      "Processing RSPd/v (Bilateral)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Completed processing condition: RSPd/v (Bilateral)\n",
      "INFO:__main__:Processing condition: VISp (L) with 8 trials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to:\n",
      "- results/results_RSPd_v (Bilateral).npz\n",
      "- results/results_RSPd_v (Bilateral).pkl\n",
      "\n",
      "Processing VISp (L)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:__main__:Error processing trial 6 for pair VISl (R)_vs_VISp (L): Matrix is not positive definite.\n",
      "WARNING:__main__:Error processing trial 6 for pair VISp (L)_vs_VISl (R): Matrix is not positive definite.\n",
      "INFO:__main__:Completed processing condition: VISp (L)\n",
      "INFO:__main__:Processing condition: MOs (R) with 8 trials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to:\n",
      "- results/results_VISp (L).npz\n",
      "- results/results_VISp (L).pkl\n",
      "\n",
      "Processing MOs (R)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:__main__:Error processing trial 4 for pair MED (R)_vs_STR (L): Matrix is not positive definite.\n",
      "WARNING:__main__:Error processing trial 4 for pair STR (L)_vs_MED (R): Matrix is not positive definite.\n",
      "INFO:__main__:Completed processing condition: MOs (R)\n",
      "INFO:__main__:Processing condition: SSp-bfd (L) with 7 trials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to:\n",
      "- results/results_MOs (R).npz\n",
      "- results/results_MOs (R).pkl\n",
      "\n",
      "Processing SSp-bfd (L)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Completed processing condition: SSp-bfd (L)\n",
      "INFO:__main__:Processing condition: VISa/rl (R) with 14 trials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to:\n",
      "- results/results_SSp-bfd (L).npz\n",
      "- results/results_SSp-bfd (L).pkl\n",
      "\n",
      "Processing VISa/rl (R)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Completed processing condition: VISa/rl (R)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to:\n",
      "- results/results_VISa_rl (R).npz\n",
      "- results/results_VISa_rl (R).pkl\n"
     ]
    }
   ],
   "source": [
    "all_conditions = [c for c in merged_data.keys() if c != 'roi_names']\n",
    "\n",
    "for cond in all_conditions:\n",
    "    print(f\"\\nProcessing {cond}...\")\n",
    "    results = analyze_roi_pairs(\n",
    "        merged_data, \n",
    "        selected_conditions=[cond],\n",
    "        n_workers=2  \n",
    "    )\n",
    "    save_path = save_results(results, cond=cond)\n",
    "    \n",
    "    del results\n",
    "    import gc; gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "topology_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
