{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "182e971b",
   "metadata": {},
   "source": [
    "# 4.2.1 BCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4309726",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import bct\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "from matplotlib.backends.backend_pdf import PdfPages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42343b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_efficiency_distribution(eff_df, network_type, atom_type):\n",
    "    \"\"\"Plot efficiency distribution boxplot with all x-axis labels right-aligned\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(5, 4))\n",
    "    palette = sns.color_palette(\"viridis\", n_colors=10)\n",
    "    \n",
    "    # Ensure 'Rest' condition comes first\n",
    "    if 'Condition' in eff_df.columns:\n",
    "        condition_order = ['Rest'] + [c for c in eff_df['Condition'].unique() if c != 'Rest']\n",
    "        eff_df['Condition'] = pd.Categorical(eff_df['Condition'], categories=condition_order, ordered=True)\n",
    "        eff_df = eff_df.sort_values('Condition')\n",
    "    \n",
    "    # Calculate and print median values per condition\n",
    "    median_values = eff_df.groupby('Condition')['Efficiency'].median()\n",
    "    print(\"Median efficiency values per condition:\")\n",
    "    print(median_values)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    sns.boxplot(\n",
    "        data=eff_df, \n",
    "        x='Condition', \n",
    "        y='Efficiency',\n",
    "        palette=palette,\n",
    "        width=0.6,\n",
    "        showfliers=False,\n",
    "        ax=ax\n",
    "    )\n",
    "    sns.stripplot(\n",
    "        data=eff_df,\n",
    "        x='Condition',\n",
    "        y='Efficiency',\n",
    "        color='black',\n",
    "        alpha=0.3,\n",
    "        size=4,\n",
    "        jitter=True,\n",
    "        ax=ax\n",
    "    )\n",
    "    \n",
    "    # ax.set_ylabel(\"Global Efficiency\")\n",
    "    ax.set_xlabel(\"\")\n",
    "    \n",
    "    # Right-align all x-axis tick labels\n",
    "    ax.set_xticks(ax.get_xticks())\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), ha='right')\n",
    "    \n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d3b4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_median_diff_heatmap(eff_df, conditions, network_type, atom_type, output_pdf='bct_median_diff_heatmap.pdf'):\n",
    "    \"\"\"Plot median condition difference heatmap\"\"\"\n",
    "    # Calculate median efficiency per condition\n",
    "    median_eff = eff_df.groupby('Condition')['Efficiency'].median()\n",
    "    \n",
    "    # Ensure \"Rest\" condition comes first\n",
    "    if 'Rest' in conditions:\n",
    "        rest_idx = conditions.index('Rest')\n",
    "        conditions = [conditions[rest_idx]] + [cond for cond in conditions if cond != 'Rest']\n",
    "        median_eff = median_eff[conditions]\n",
    "    \n",
    "    # Create difference matrix\n",
    "    n_conds = len(conditions)\n",
    "    diff_matrix = np.zeros((n_conds, n_conds))\n",
    "    for i in range(n_conds):\n",
    "        for j in range(n_conds):\n",
    "            diff_matrix[i,j] = median_eff[i] - median_eff[j]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(6, 5))\n",
    "    \n",
    "    diff_df = pd.DataFrame(\n",
    "        diff_matrix * 100,  # Multiply by 100\n",
    "        index=conditions,\n",
    "        columns=conditions\n",
    "    )\n",
    "    \n",
    "    # Create annotation matrix\n",
    "    annot_matrix = np.empty_like(diff_matrix, dtype=object)\n",
    "    for i in range(n_conds):\n",
    "        for j in range(n_conds):\n",
    "            if i == j:\n",
    "                annot_matrix[i,j] = ''\n",
    "            else:\n",
    "                value = diff_matrix[i,j] * 100  # Convert to x10^-2\n",
    "                annot_matrix[i,j] = f\"{value:.2f}\"\n",
    "    \n",
    "    # Plot heatmap - note vmin/vmax also multiplied by 100\n",
    "    heatmap = sns.heatmap(\n",
    "        diff_df,\n",
    "        annot=annot_matrix,\n",
    "        fmt='',\n",
    "        cmap='coolwarm',\n",
    "        center=0,\n",
    "        vmin=-np.max(np.abs(diff_matrix)) * 100,  # Multiplied by 100\n",
    "        vmax=np.max(np.abs(diff_matrix)) * 100,   # Multiplied by 100\n",
    "        cbar_kws={\n",
    "            'label': 'Median Efficiency Difference (Ã—10^-2)',\n",
    "            'format': '%0.1f'  # Colorbar with 1 decimal\n",
    "        },\n",
    "        ax=ax\n",
    "    )\n",
    "\n",
    "    # Rotate x-axis labels 45 degrees\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "\n",
    "    if output_pdf:\n",
    "        plt.savefig(output_pdf, format='pdf', bbox_inches='tight', dpi=300)\n",
    "        print(f\"PDF saved to: {output_pdf}\")\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0236eb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pvalue_heatmap(pval_matrix_fdr, conditions, network_type, atom_type):\n",
    "    \"\"\"Plot p-value heatmap with FDR correction\"\"\"\n",
    "    # Ensure \"Rest\" condition comes first\n",
    "    if 'Rest' in conditions:\n",
    "        rest_idx = conditions.index('Rest')\n",
    "        conditions = [conditions[rest_idx]] + [cond for cond in conditions if cond != 'Rest']\n",
    "        pval_matrix_fdr = pval_matrix_fdr[np.ix_([rest_idx] + [i for i in range(len(conditions)) if i != rest_idx], \n",
    "                                               [rest_idx] + [i for i in range(len(conditions)) if i != rest_idx])]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(6, 5))\n",
    "    \n",
    "    # Convert to -log10(p)\n",
    "    log_p_matrix = -np.log10(pval_matrix_fdr)\n",
    "    log_p_df = pd.DataFrame(\n",
    "        log_p_matrix, \n",
    "        index=conditions, \n",
    "        columns=conditions\n",
    "    )\n",
    "    \n",
    "    # Create mask for non-significant regions\n",
    "    mask = pval_matrix_fdr >= 0.05\n",
    "    \n",
    "    # Create annotation matrix (showing -log10(p) values)\n",
    "    annot_matrix = np.empty_like(pval_matrix_fdr, dtype=object)\n",
    "    for i in range(len(conditions)):\n",
    "        for j in range(len(conditions)):\n",
    "            if i == j:\n",
    "                annot_matrix[i,j] = ''\n",
    "            else:\n",
    "                p = pval_matrix_fdr[i,j]\n",
    "                if p < 0.05:\n",
    "                    annot_matrix[i,j] = f\"{log_p_matrix[i,j]:.2f}\"\n",
    "                else:\n",
    "                    annot_matrix[i,j] = f\"{log_p_matrix[i,j]:.2f}\"  # Still show value but with gray background\n",
    "    \n",
    "    # Plot significant heatmap\n",
    "    sns.heatmap(\n",
    "        log_p_df,\n",
    "        annot=annot_matrix,\n",
    "        fmt='',\n",
    "        cmap='YlOrRd',\n",
    "        vmin=0,\n",
    "        vmax=-np.log10(0.001),  # Corresponds to p=0.001\n",
    "        cbar_kws={'label': '-log10(FDR-corrected p-value)'},\n",
    "        ax=ax,\n",
    "        mask=mask\n",
    "    )\n",
    "    \n",
    "    # Add gray background for non-significant regions\n",
    "    sns.heatmap(\n",
    "        log_p_df,\n",
    "        annot=annot_matrix,\n",
    "        fmt='',\n",
    "        cmap=['lightgray'],\n",
    "        vmin=0,\n",
    "        vmax=1,\n",
    "        cbar=False,\n",
    "        ax=ax,\n",
    "        mask=~mask\n",
    "    )\n",
    "    \n",
    "    # Rotate x-axis labels 45 degrees\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e453371",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_effect_size_heatmap(effect_size_matrix, conditions, network_type, atom_type, pval_matrix_fdr=None):\n",
    "    \"\"\"Plot effect size heatmap with optional significance masking\"\"\"\n",
    "    # Ensure \"Rest\" condition comes first\n",
    "    if 'Rest' in conditions:\n",
    "        rest_idx = conditions.index('Rest')\n",
    "        conditions = [conditions[rest_idx]] + [cond for cond in conditions if cond != 'Rest']\n",
    "        effect_size_matrix = effect_size_matrix[np.ix_([rest_idx] + [i for i in range(len(conditions)) if i != rest_idx], \n",
    "                                                     [rest_idx] + [i for i in range(len(conditions)) if i != rest_idx])]\n",
    "        if pval_matrix_fdr is not None:\n",
    "            pval_matrix_fdr = pval_matrix_fdr[np.ix_([rest_idx] + [i for i in range(len(conditions)) if i != rest_idx], \n",
    "                                                    [rest_idx] + [i for i in range(len(conditions)) if i != rest_idx])]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(6, 5))\n",
    "    \n",
    "    effect_df = pd.DataFrame(\n",
    "        effect_size_matrix,\n",
    "        index=conditions,\n",
    "        columns=conditions\n",
    "    )\n",
    "    \n",
    "    # Create mask - diagonal or non-significant regions\n",
    "    mask = np.zeros_like(effect_size_matrix, dtype=bool)\n",
    "    np.fill_diagonal(mask, True)  # Mask diagonal\n",
    "    \n",
    "    if pval_matrix_fdr is not None:\n",
    "        # Add non-significant regions to mask\n",
    "        mask = mask | (pval_matrix_fdr >= 0.05)\n",
    "    \n",
    "    # Prepare annotation text\n",
    "    annot_matrix = np.empty_like(effect_size_matrix, dtype=object)\n",
    "    for i in range(len(conditions)):\n",
    "        for j in range(len(conditions)):\n",
    "            if i == j:\n",
    "                annot_matrix[i,j] = ''\n",
    "            else:\n",
    "                annot_matrix[i,j] = f\"{effect_size_matrix[i,j]:.2f}\"\n",
    "    \n",
    "    # Plot main heatmap (significant regions)\n",
    "    sns.heatmap(\n",
    "        effect_df,\n",
    "        annot=annot_matrix,\n",
    "        fmt='',\n",
    "        cmap='coolwarm',\n",
    "        center=0,\n",
    "        vmin=-2,\n",
    "        vmax=2,\n",
    "        cbar_kws={'label': \"Cohen's d\"},\n",
    "        ax=ax,\n",
    "        mask=mask\n",
    "    )\n",
    "    \n",
    "    # Plot gray background for non-significant regions\n",
    "    sns.heatmap(\n",
    "        effect_df,\n",
    "        annot=annot_matrix,\n",
    "        fmt='',\n",
    "        cmap=['lightgray'],\n",
    "        center=0,\n",
    "        vmin=-2,\n",
    "        vmax=2,\n",
    "        cbar=False,\n",
    "        ax=ax,\n",
    "        mask=~mask\n",
    "    )\n",
    "    \n",
    "    # Rotate x-axis labels 45 degrees\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0dfe5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_trial_efficiencies(results_dir='results', network_type='TE', atom_type='xty'):\n",
    "    \"\"\"\n",
    "    Main analysis function that returns statistical results and three plot objects\n",
    "    \n",
    "    Args:\n",
    "        results_dir: Directory containing result files\n",
    "        network_type: Network type ('TE', 'PhiID', 'PID')\n",
    "        atom_type: Atom type (used when network_type is 'PhiID' or 'PID')\n",
    "    \"\"\"\n",
    "    # Collect efficiency data for all conditions\n",
    "    efficiency_data = defaultdict(list)\n",
    "    result_files = glob.glob(os.path.join(results_dir, '*.pkl'))\n",
    "    \n",
    "    for filepath in sorted(result_files):\n",
    "        try:\n",
    "            with open(filepath, 'rb') as f:\n",
    "                file_results = pickle.load(f)\n",
    "            \n",
    "            # Extract condition name from filename\n",
    "            filename = os.path.basename(filepath)\n",
    "            cond_match = re.search(r'results_(.*?)\\.pkl', filename)\n",
    "            cond = cond_match.group(1) if cond_match else filename.replace('.pkl', '')\n",
    "            \n",
    "            # Get ROI information\n",
    "            roi_names = file_results.get('metadata', {}).get('roi_names', [])\n",
    "            n_rois = len(roi_names)\n",
    "            if n_rois == 0:\n",
    "                print(f\"No ROI names found in {filename}\")\n",
    "                continue\n",
    "            \n",
    "            trial_matrices = []\n",
    "            \n",
    "            # Process each condition in the file\n",
    "            for cond_key, cond_data in file_results.get('conditions', {}).items():\n",
    "                n_trials = None\n",
    "                \n",
    "                # Determine number of trials\n",
    "                for pair_key, pair_data in cond_data.get('roi_pairs', {}).items():\n",
    "                    if 'error' in pair_data:\n",
    "                        continue\n",
    "                    \n",
    "                    # Get trial values based on network type\n",
    "                    if network_type == 'TE':\n",
    "                        trial_values = pair_data.get('TE', {}).get('values', [])\n",
    "                    elif network_type == 'PhiID':\n",
    "                        trial_values = pair_data.get('PhiID', {}).get('trial_values', {}).get(atom_type, [])\n",
    "                    elif network_type == 'PID':\n",
    "                        trial_values = pair_data.get('PID', {}).get('trial_values', {}).get(atom_type, [])\n",
    "                    else:\n",
    "                        trial_values = []\n",
    "                    \n",
    "                    # Ensure trial_values is a flat list of numbers\n",
    "                    if isinstance(trial_values, (list, np.ndarray)) and len(trial_values) > 0:\n",
    "                        if hasattr(trial_values[0], '__len__') and not isinstance(trial_values[0], str):\n",
    "                            trial_values = [val[0] if hasattr(val, '__len__') else val for val in trial_values]\n",
    "                    \n",
    "                    # Initialize trial matrices\n",
    "                    if n_trials is None and trial_values:\n",
    "                        n_trials = len(trial_values)\n",
    "                        trial_matrices = [np.zeros((n_rois, n_rois)) for _ in range(n_trials)]\n",
    "                    \n",
    "                    # Populate trial matrices\n",
    "                    if n_trials is not None:\n",
    "                        src, tgt = pair_data['roi_info']['indices']\n",
    "                        for trial_idx, val in enumerate(trial_values):\n",
    "                            if trial_idx < n_trials:\n",
    "                                if hasattr(val, '__len__') and not isinstance(val, str):\n",
    "                                    val = val[0]\n",
    "                                trial_matrices[trial_idx][src, tgt] = float(val) if val is not None else 0.0\n",
    "            \n",
    "            # Calculate efficiency for each trial\n",
    "            for mat in trial_matrices:\n",
    "                try:\n",
    "                    mat = np.nan_to_num(mat, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "                    eff = bct.efficiency_wei(mat)\n",
    "                    efficiency_data[cond].append(eff)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error calculating efficiency for {cond}: {str(e)}\")\n",
    "                    continue\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {os.path.basename(filepath)}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    if not efficiency_data:\n",
    "        print(\"No efficiency data found!\")\n",
    "        return None, None, None, None\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    eff_list = []\n",
    "    for cond, effs in efficiency_data.items():\n",
    "        for eff in effs:\n",
    "            eff_list.append({'Condition': cond, 'Efficiency': eff})\n",
    "    eff_df = pd.DataFrame(eff_list)\n",
    "    \n",
    "    # Calculate descriptive statistics\n",
    "    condition_stats = eff_df.groupby('Condition')['Efficiency'].agg(['mean', 'median', 'std', 'count'])\n",
    "    \n",
    "    # Perform pairwise comparisons\n",
    "    conditions = sorted(efficiency_data.keys())\n",
    "    n_conds = len(conditions)\n",
    "    \n",
    "    pval_matrix = np.ones((n_conds, n_conds))\n",
    "    effect_size_matrix = np.zeros((n_conds, n_conds))\n",
    "    \n",
    "    for i, j in itertools.combinations(range(n_conds), 2):\n",
    "        cond1, cond2 = conditions[i], conditions[j]\n",
    "        data1 = efficiency_data[cond1]\n",
    "        data2 = efficiency_data[cond2]\n",
    "        \n",
    "        if len(data1) > 0 and len(data2) > 0:\n",
    "            try:\n",
    "                u_stat, p_val = stats.mannwhitneyu(data1, data2, alternative='two-sided')\n",
    "                pval_matrix[i, j] = p_val\n",
    "                pval_matrix[j, i] = p_val\n",
    "                \n",
    "                pooled_std = np.sqrt(((len(data1)-1)*np.std(data1)**2 + (len(data2)-1)*np.std(data2)**2) / \n",
    "                                (len(data1) + len(data2) - 2))\n",
    "                effect_size = (np.mean(data1) - np.mean(data2)) / pooled_std\n",
    "                effect_size_matrix[i, j] = effect_size\n",
    "                effect_size_matrix[j, i] = -effect_size\n",
    "            except Exception as e:\n",
    "                print(f\"Error comparing {cond1} vs {cond2}: {str(e)}\")\n",
    "    \n",
    "    # FDR correction\n",
    "    pvals = pval_matrix[np.triu_indices_from(pval_matrix, k=1)]\n",
    "    if len(pvals) > 0:\n",
    "        _, pvals_fdr = fdrcorrection(pvals)\n",
    "        pval_matrix_fdr = np.copy(pval_matrix)\n",
    "        pval_matrix_fdr[np.triu_indices_from(pval_matrix_fdr, k=1)] = pvals_fdr\n",
    "        pval_matrix_fdr[np.tril_indices_from(pval_matrix_fdr, k=-1)] = pvals_fdr\n",
    "    else:\n",
    "        pval_matrix_fdr = pval_matrix\n",
    "    \n",
    "    # Generate plots\n",
    "    fig_dist = plot_efficiency_distribution(eff_df, network_type, atom_type)\n",
    "    fig_pval = plot_pvalue_heatmap(pval_matrix_fdr, conditions, network_type, atom_type)\n",
    "    fig_effect = plot_effect_size_heatmap(effect_size_matrix, conditions, network_type, atom_type)\n",
    "    \n",
    "    # Return results and figures\n",
    "    stats_results = {\n",
    "        'condition_stats': condition_stats,\n",
    "        'pairwise_pvals': pval_matrix,\n",
    "        'pairwise_pvals_fdr': pval_matrix_fdr,\n",
    "        'effect_sizes': effect_size_matrix,\n",
    "        'network_type': network_type,\n",
    "        'atom_type': atom_type,\n",
    "        'efficiency_data': efficiency_data\n",
    "    }\n",
    "    \n",
    "    return stats_results, fig_dist, fig_pval, fig_effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aec3b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_results, fig_dist, fig_pval, fig_effect = analyze_trial_efficiencies(results_dir='results')\n",
    "\n",
    "with open(\"efficiency_stats.pkl\", 'wb') as f:\n",
    "    pickle.dump(stats_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9affc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_dist.savefig(\"efficiency_distribution.pdf\", bbox_inches='tight')\n",
    "fig_pval.savefig(\"pvalue_heatmap.pdf\", bbox_inches='tight')\n",
    "fig_effect.savefig(\"effect_size_heatmap.pdf\", bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nii_analysis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
